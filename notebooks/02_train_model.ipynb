{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18ab2cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n",
      "Epoch 1/50\n",
      "898/898 [==============================] - 97s 107ms/step - loss: 1.7895 - accuracy: 0.2570 - val_loss: 1.7036 - val_accuracy: 0.3130\n",
      "Epoch 2/50\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 1.6856 - accuracy: 0.3220 - val_loss: 1.4992 - val_accuracy: 0.4181\n",
      "Epoch 3/50\n",
      "898/898 [==============================] - 115s 128ms/step - loss: 1.5606 - accuracy: 0.3910 - val_loss: 1.3784 - val_accuracy: 0.4798\n",
      "Epoch 4/50\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 1.4667 - accuracy: 0.4359 - val_loss: 1.3690 - val_accuracy: 0.4774\n",
      "Epoch 5/50\n",
      "898/898 [==============================] - 23s 26ms/step - loss: 1.4231 - accuracy: 0.4545 - val_loss: 1.2985 - val_accuracy: 0.5085\n",
      "Epoch 6/50\n",
      "898/898 [==============================] - 21s 24ms/step - loss: 1.3882 - accuracy: 0.4733 - val_loss: 1.2722 - val_accuracy: 0.5131\n",
      "Epoch 7/50\n",
      "898/898 [==============================] - 21s 23ms/step - loss: 1.3556 - accuracy: 0.4831 - val_loss: 1.2432 - val_accuracy: 0.5138\n",
      "Epoch 8/50\n",
      "898/898 [==============================] - 21s 23ms/step - loss: 1.3386 - accuracy: 0.4927 - val_loss: 1.2491 - val_accuracy: 0.5230\n",
      "Epoch 9/50\n",
      "898/898 [==============================] - 21s 23ms/step - loss: 1.3193 - accuracy: 0.4973 - val_loss: 1.2279 - val_accuracy: 0.5352\n",
      "Epoch 10/50\n",
      "898/898 [==============================] - 21s 23ms/step - loss: 1.3007 - accuracy: 0.5051 - val_loss: 1.1797 - val_accuracy: 0.5515\n",
      "Epoch 11/50\n",
      "898/898 [==============================] - 21s 23ms/step - loss: 1.2893 - accuracy: 0.5098 - val_loss: 1.1788 - val_accuracy: 0.5528\n",
      "Epoch 12/50\n",
      "898/898 [==============================] - 21s 23ms/step - loss: 1.2815 - accuracy: 0.5172 - val_loss: 1.1926 - val_accuracy: 0.5475\n",
      "Epoch 13/50\n",
      "898/898 [==============================] - 21s 24ms/step - loss: 1.2709 - accuracy: 0.5193 - val_loss: 1.1516 - val_accuracy: 0.5658\n",
      "Epoch 14/50\n",
      "898/898 [==============================] - 24s 27ms/step - loss: 1.2608 - accuracy: 0.5233 - val_loss: 1.1583 - val_accuracy: 0.5641\n",
      "Epoch 15/50\n",
      "898/898 [==============================] - 25s 28ms/step - loss: 1.2536 - accuracy: 0.5297 - val_loss: 1.1976 - val_accuracy: 0.5454\n",
      "Epoch 16/50\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 1.2415 - accuracy: 0.5297 - val_loss: 1.1506 - val_accuracy: 0.5610\n",
      "Epoch 17/50\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 1.2403 - accuracy: 0.5344 - val_loss: 1.1412 - val_accuracy: 0.5639\n",
      "Epoch 18/50\n",
      "898/898 [==============================] - 24s 27ms/step - loss: 1.2296 - accuracy: 0.5373 - val_loss: 1.1293 - val_accuracy: 0.5745\n",
      "Epoch 19/50\n",
      "898/898 [==============================] - 82s 92ms/step - loss: 1.2210 - accuracy: 0.5371 - val_loss: 1.1316 - val_accuracy: 0.5688\n",
      "Epoch 20/50\n",
      "898/898 [==============================] - 124s 138ms/step - loss: 1.2245 - accuracy: 0.5382 - val_loss: 1.1487 - val_accuracy: 0.5694\n",
      "Epoch 21/50\n",
      "898/898 [==============================] - 402s 448ms/step - loss: 1.2133 - accuracy: 0.5434 - val_loss: 1.1244 - val_accuracy: 0.5752\n",
      "Epoch 22/50\n",
      "898/898 [==============================] - 148s 164ms/step - loss: 1.2069 - accuracy: 0.5466 - val_loss: 1.1137 - val_accuracy: 0.5791\n",
      "Epoch 23/50\n",
      "898/898 [==============================] - 23s 26ms/step - loss: 1.2000 - accuracy: 0.5464 - val_loss: 1.1231 - val_accuracy: 0.5777\n",
      "Epoch 24/50\n",
      "898/898 [==============================] - 23s 25ms/step - loss: 1.1996 - accuracy: 0.5464 - val_loss: 1.1214 - val_accuracy: 0.5780\n",
      "Epoch 25/50\n",
      "898/898 [==============================] - 21s 23ms/step - loss: 1.2010 - accuracy: 0.5484 - val_loss: 1.1201 - val_accuracy: 0.5828\n",
      "Epoch 26/50\n",
      "898/898 [==============================] - 21s 24ms/step - loss: 1.1982 - accuracy: 0.5490 - val_loss: 1.1153 - val_accuracy: 0.5777\n",
      "Epoch 27/50\n",
      "898/898 [==============================] - 21s 23ms/step - loss: 1.1848 - accuracy: 0.5544 - val_loss: 1.1054 - val_accuracy: 0.5818\n",
      "Epoch 28/50\n",
      "898/898 [==============================] - 21s 23ms/step - loss: 1.1870 - accuracy: 0.5504 - val_loss: 1.1003 - val_accuracy: 0.5800\n",
      "Epoch 29/50\n",
      "898/898 [==============================] - 21s 23ms/step - loss: 1.1842 - accuracy: 0.5536 - val_loss: 1.1081 - val_accuracy: 0.5823\n",
      "Epoch 30/50\n",
      "898/898 [==============================] - 21s 23ms/step - loss: 1.1781 - accuracy: 0.5535 - val_loss: 1.0845 - val_accuracy: 0.5911\n",
      "Epoch 31/50\n",
      "898/898 [==============================] - 21s 23ms/step - loss: 1.1737 - accuracy: 0.5579 - val_loss: 1.1115 - val_accuracy: 0.5763\n",
      "Epoch 32/50\n",
      "898/898 [==============================] - 21s 24ms/step - loss: 1.1724 - accuracy: 0.5591 - val_loss: 1.0813 - val_accuracy: 0.5899\n",
      "Epoch 33/50\n",
      "898/898 [==============================] - 21s 23ms/step - loss: 1.1700 - accuracy: 0.5583 - val_loss: 1.1042 - val_accuracy: 0.5790\n",
      "Epoch 34/50\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 1.1667 - accuracy: 0.5592 - val_loss: 1.1131 - val_accuracy: 0.5801\n",
      "Epoch 35/50\n",
      "898/898 [==============================] - 24s 27ms/step - loss: 1.1654 - accuracy: 0.5595 - val_loss: 1.0908 - val_accuracy: 0.5889\n",
      "Epoch 36/50\n",
      "898/898 [==============================] - 23s 25ms/step - loss: 1.1635 - accuracy: 0.5622 - val_loss: 1.0762 - val_accuracy: 0.5989\n",
      "Epoch 37/50\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 1.1618 - accuracy: 0.5615 - val_loss: 1.0800 - val_accuracy: 0.5913\n",
      "Epoch 38/50\n",
      "898/898 [==============================] - 21s 23ms/step - loss: 1.1570 - accuracy: 0.5636 - val_loss: 1.0836 - val_accuracy: 0.5907\n",
      "Epoch 39/50\n",
      "898/898 [==============================] - 21s 23ms/step - loss: 1.1513 - accuracy: 0.5652 - val_loss: 1.0834 - val_accuracy: 0.5925\n",
      "Epoch 40/50\n",
      "898/898 [==============================] - 21s 23ms/step - loss: 1.1533 - accuracy: 0.5649 - val_loss: 1.0918 - val_accuracy: 0.5915\n",
      "Epoch 41/50\n",
      "897/898 [============================>.] - ETA: 0s - loss: 1.1483 - accuracy: 0.5697Restoring model weights from the end of the best epoch: 36.\n",
      "898/898 [==============================] - 21s 23ms/step - loss: 1.1483 - accuracy: 0.5696 - val_loss: 1.0833 - val_accuracy: 0.5938\n",
      "Epoch 41: early stopping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")  \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from src.cnn_model import build_emotion_model\n",
    "\n",
    "train_dir = r\"D:\\emotion_detection\\dataset\\train\"\n",
    "test_dir = r\"D:\\emotion_detection\\dataset\\test\"\n",
    "\n",
    "#Load data\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 15,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    shear_range = 0.1,\n",
    "    zoom_range = 0.1,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "test_gen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_data = train_gen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(48, 48),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_data = test_gen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(48, 48),\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "#build model\n",
    "model = build_emotion_model()\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    min_delta = 0.001,\n",
    "    patience = 5,\n",
    "    verbose = 1,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data = test_data,\n",
    "    epochs = 50,\n",
    "    callbacks = [early_stop],\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "model.save(\"../models/emotion_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8427977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn_gpu_env",
   "language": "python",
   "name": "cnn_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
